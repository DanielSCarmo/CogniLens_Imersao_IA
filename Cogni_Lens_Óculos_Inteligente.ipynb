{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielSCarmo/CogniLens_Imersao_IA/blob/main/Cogni_Lens_%C3%93culos_Inteligente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto/Protótipo\n",
        "Nosso projeto consiste no desenvolvimento de um protótipo inicial de óculos integrado com a inteligência artificial Gemini. O dispositivo incluirá uma câmera e um fone de ouvido para a transmissão e recebimento de informações da IA. Optamos por utilizar o Code Visual Studio para o desenvolvimento do código, uma vez que o Colab apresentou restrições no acesso à câmera e ao áudio. Este enfoque visa simplificar ao máximo a implementação inicial do projeto.\n",
        "**\\ O código não roda no Colab! /**"
      ],
      "metadata": {
        "id": "XAC4_7BYu-y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baixar as bibliotecas usadas"
      ],
      "metadata": {
        "id": "JB8R36Jtc06j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Opencv-python\n",
        "!pip install SpeechRecognition\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!pip install pyaudio\n",
        "!pip install pyttsx3\n",
        "!pip install matplotlib\n",
        "!pip install tk\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "Yy4NVI1bcQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando as bibliotecas"
      ],
      "metadata": {
        "id": "qo5BUwPTc95y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pyaudio\n",
        "import wave\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "import speech_recognition as sr\n",
        "import tkinter as tk\n",
        "import pyttsx3\n",
        "import threading"
      ],
      "metadata": {
        "id": "261a119ueT66"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Esperando o usuario falar Ok Gemini para começar o comando"
      ],
      "metadata": {
        "id": "my_oyDrCdDTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Há duas chaves api pois foi feito em grupo\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('Chave_secreta')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "api_key = userdata.get('Chave_secreta2')\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "bwZy1lamunLY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como é apenas um protótipo, substituimos o OK Gemini por apertar a tecla Q\n",
        "# que vai começar a executar o código abaixo que é o comando para o Gemini\n",
        "\n",
        "# Inicializa o reconhecedor de fala\n",
        "reconhecedor = sr.Recognizer()\n",
        "\n",
        "# Variável para controlar a execução da transcrição\n",
        "executando = True\n",
        "\n",
        "# Função para transcrever o áudio e atualizar o texto na janela\n",
        "def transcrever_audio():\n",
        "    global executando\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Diga algo!\")\n",
        "        # Escuta o áudio do microfone\n",
        "        audio = reconhecedor.listen(source, phrase_time_limit=10)  # Limita o tempo de escuta a 5 segundos\n",
        "\n",
        "        try:\n",
        "            # Usa o Google Speech Recognition para transcrever o áudio em texto\n",
        "            texto = reconhecedor.recognize_google(audio, language=\"pt-BR\")  # Define o idioma como português do Brasil\n",
        "            if texto:\n",
        "                resultado_label.config(text=\"Você disse: \" + texto)\n",
        "        except sr.UnknownValueError:\n",
        "            resultado_label.config(text=\"Não foi possível entender o áudio\")\n",
        "        except sr.RequestError as e:\n",
        "            resultado_label.config(text=\"Erro no serviço de reconhecimento de fala; {0}\".format(e))\n",
        "\n",
        "        # Agendar a próxima transcrição após 1000 milissegundos, se a variável executando for True\n",
        "        if executando:\n",
        "            janela.after(1000, transcrever_audio)\n",
        "\n",
        "# Função para encerrar o programa\n",
        "def encerrar_programa(event):\n",
        "    global executando\n",
        "    if event.keysym == 'q':\n",
        "        executando = False\n",
        "        janela.destroy()\n",
        "\n",
        "# Cria a janela\n",
        "janela = tk.Tk()\n",
        "janela.title(\"Transcrição de Áudio\")\n",
        "\n",
        "# Cria um rótulo para exibir o resultado da transcrição\n",
        "resultado_label = tk.Label(janela, text=\"\")\n",
        "resultado_label.pack()\n",
        "\n",
        "# Inicia a transcrição do áudio em uma thread separada\n",
        "threading.Thread(target=transcrever_audio).start()\n",
        "\n",
        "# Associa a função de encerramento do programa ao pressionar uma tecla\n",
        "janela.bind('<Key>', encerrar_programa)\n",
        "\n",
        "# Inicia o loop principal da janela\n",
        "janela.mainloop()"
      ],
      "metadata": {
        "id": "EDiJtTW4eTma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Começar o comando para o Gemini"
      ],
      "metadata": {
        "id": "WiS40hCbdOaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializa o gravador de vídeo\n",
        "frame_width = 640\n",
        "frame_height = 480\n",
        "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 20, (frame_width, frame_height))\n",
        "\n",
        "# Inicializa o gravador de áudio\n",
        "audio = pyaudio.PyAudio()\n",
        "stream = audio.open(format=pyaudio.paInt16, channels=1, rate=44100, input=True, frames_per_buffer=1024)\n",
        "frames = []\n",
        "\n",
        "# Captura de vídeo\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while(True):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        # Escreve o frame no arquivo de vídeo\n",
        "        out.write(frame)\n",
        "        cv2.imshow('Video', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "    # Captura o áudio\n",
        "    data = stream.read(1024)\n",
        "    frames.append(data)\n",
        "\n",
        "# Libera os recursos\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "audio.terminate()\n",
        "\n",
        "# Salva o áudio em um arquivo WAV\n",
        "wf = wave.open(\"output_audio.wav\", 'wb')\n",
        "wf.setnchannels(1)\n",
        "wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
        "wf.setframerate(44100)\n",
        "wf.writeframes(b''.join(frames))\n",
        "wf.close()"
      ],
      "metadata": {
        "id": "Yqf_iJFoeUSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "At the command line, only need to run once to install the package via pip:\n",
        "\n",
        "$ pip install google-generativeai\n",
        "\"\"\"\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.57,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 0,\n",
        "  \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
        "  },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "def extract_video_frames(pathname: str) -> list:\n",
        "  # See https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video.ipynb\n",
        "  return []\n",
        "\n",
        "prompt_parts = [\n",
        "  \"\\nListen to the audio, try to understand what is being said and respond to the audio command:\\n\",\n",
        "  genai.upload_file(\"output_audio.wav\"),\n",
        "  \"\\nrespond to the audio using the following video as a parameter:\\n\",\n",
        "  *extract_video_frames(\"output.avi\"),\n",
        "  \"\\nrespond in Portuguese (Brazil)\",\n",
        "]\n",
        "\n",
        "response = model.generate_content(prompt_parts)\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "AYsmNc-De4iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resposta em áudio"
      ],
      "metadata": {
        "id": "r1tXg30hfbCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speak(text):\n",
        "    engine = pyttsx3.init()\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()\n",
        "\n",
        "# Exemplo de uso\n",
        "#response = \"Olá, eu sou o Gemini. Como posso ajudá-lo hoje?\"\n",
        "#speak(response)\n",
        "speak(response.text)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wtodb6nRcPvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}